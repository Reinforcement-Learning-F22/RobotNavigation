{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyiN4d52a0pC"
      },
      "source": [
        "# Deep Q-Network (DQN)\n",
        "\n",
        "**Description:** Implementing DQN algorithm on the Robot Navigation Problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0ryZIi8a0pI"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "**Deep Q-Network (DQN)** is a model-free off-policy algorithm for learning discrete actions.\n",
        "\n",
        "It uses neural networks to apply function approximation, to estimate the Q-function while avoiding convergence problems in the case of continous actions space, states space or both.\n",
        "\n",
        "It uses a method called replayed memory, which represents a memory buffer for storing the experiences of the agent.\n",
        "\n",
        "## Problem\n",
        "\n",
        "We are trying to solve the **Robot Navigation** problem.\n",
        "In this setting, we can assume taking three actions: [Forward, LeftTurn, RightTurn].\n",
        "\n",
        "\n",
        "The implementation of the algorithm is carried out in the rest of the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HMEkgsIva0pL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import mean_squared_error\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.n_actions = action_size\n",
        "        '''\n",
        "        # \"lr\" : learning rate\n",
        "        # \"gamma\": discounted factor\n",
        "        # \"exploration_proba_decay\": decay of the exploration probability\n",
        "        # \"batch_size\": size of experiences we sample to train the DNN\n",
        "        '''\n",
        "        self.lr = 0.001\n",
        "        self.gamma = 0.99\n",
        "        self.exploration_proba = 1.0\n",
        "        self.exploration_proba_decay = 0.005\n",
        "        self.batch_size = 32\n",
        "        \n",
        "        # We define our memory buffer where we will store our experiences\n",
        "        # We stores only the 2000 last time steps\n",
        "        self.memory_buffer= list()\n",
        "        self.max_memory_buffer = 2000\n",
        "        \n",
        "        # We create our model having to hidden layers of 24 units (neurones)\n",
        "        # The first layer has the same size as a state size\n",
        "        # The last layer has the size of actions space\n",
        "        self.model = Sequential([\n",
        "            Dense(units=24,input_dim=state_size, activation = 'relu'),\n",
        "            Dense(units=24,activation = 'relu'),\n",
        "            Dense(units=action_size, activation = 'linear')\n",
        "        ])\n",
        "        self.model.compile(loss=\"mse\",\n",
        "                      optimizer = Adam(lr=self.lr))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
